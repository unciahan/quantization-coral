{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlOFTqGn-j0J"
      },
      "outputs": [],
      "source": [
        "# Install TF, TFH \n",
        "!pip install tf-nightly\n",
        "!pip install -q -U tf-hub-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvlhBzwY-o3U"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w97eqOl-wkl"
      },
      "outputs": [],
      "source": [
        "# Download Image Classification model\n",
        "\n",
        "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wH6caqNR-y3r"
      },
      "outputs": [],
      "source": [
        "# Set Classifier\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "classifier = tf.keras.Sequential([\n",
        "    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BidF69K-1Cy"
      },
      "outputs": [],
      "source": [
        "# Download test image\n",
        "\n",
        "grace_hopper = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
        "grace_hopper = Image.open(grace_hopper).resize(IMAGE_SHAPE)\n",
        "grace_hopper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJj3s2Zj_Z95"
      },
      "outputs": [],
      "source": [
        "# Add batch dimension\n",
        "\n",
        "grace_hopper = np.array(grace_hopper)/255.0\n",
        "grace_hopper.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF0RmnGs_dXa"
      },
      "outputs": [],
      "source": [
        "# Run model : result as 1001 element vecotr of logits, rating probability of each class\n",
        "\n",
        "result = classifier.predict(grace_hopper[np.newaxis, ...])\n",
        "result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX4zX8OO_hvB"
      },
      "outputs": [],
      "source": [
        "# Find prediction\n",
        "\n",
        "predicted_class = np.argmax(result[0], axis=-1)\n",
        "predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktR75_J__kKu"
      },
      "outputs": [],
      "source": [
        "# Download ImageNet labels\n",
        "\n",
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkyzEcY__mwX"
      },
      "outputs": [],
      "source": [
        "# Decode prediction\n",
        "\n",
        "plt.imshow(grace_hopper)\n",
        "plt.axis('off')\n",
        "predicted_class_name = imagenet_labels[predicted_class]\n",
        "_ = plt.title(\"Prediction: \" + predicted_class_name.title())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71DodmFCAb_8"
      },
      "outputs": [],
      "source": [
        "# Export model\n",
        "\n",
        "import time\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "export_path = \"/content/saved_models/{}\".format(int(t))\n",
        "classifier.save(export_path)\n",
        "\n",
        "export_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdethq3YA9yZ",
        "outputId": "a23884ac-9061-4b53-8226-107b75b9db15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13976588"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert SavedModel file to TFL file\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save model\n",
        "\n",
        "with open('model_default.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "# Print size of model\n",
        "\n",
        "p = pathlib.Path('model_default.tflite')\n",
        "p.write_bytes(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3iwqn564W6ix",
        "outputId": "34cc472f-f0ca-4267-e1a1-ed8d14a98579"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f7f6c665-4997-486c-82be-d5864c4233a8\", \"model_default.tflite\", 13976588)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download model\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"model_default.tflite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV0iQNyUBRSb",
        "outputId": "94063f6b-5404-4b8e-db2a-892af91c2f39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3932240"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to Dynamic range quantization model (DRQ)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save model\n",
        "\n",
        "with open('model_drq.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "# Print size of model\n",
        "\n",
        "p = pathlib.Path('model_drq.tflite')\n",
        "p.write_bytes(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JQIjZXGqWeLV",
        "outputId": "aaeaa01d-885f-4e37-937c-effbba642434"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d06f1cf3-91df-493b-b4e5-ce8cc3c06d82\", \"model_drq.tflite\", 13976588)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download model\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"model_drq.tflite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfFi4_TlBRfZ",
        "outputId": "008c5f72-b96a-4c5c-8394-8687909d5971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7010912"
            ]
          },
          "execution_count": 43,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to Float16 quantization model (F16Q)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save model\n",
        "\n",
        "with open('model_f16q.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "# Print size of model\n",
        "\n",
        "p = pathlib.Path('model_f16q.tflite')\n",
        "p.write_bytes(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-39wTDv-WfFZ",
        "outputId": "0be9e893-6c4e-4784-f6cf-ee38858c69cb"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_aa1e19a9-814e-404f-b800-62f4827f2a46\", \"model_f16q.tflite\", 13976588)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download model\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"model_f16q.tflite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "rcjQx0ISBY5v",
        "outputId": "36b99e90-159c-49e6-ac46-9c4bda378b36"
      },
      "outputs": [],
      "source": [
        "# Convert to Float fallback integer quantization (FFIQ)\n",
        "\n",
        "# Load reperesenative dataset\n",
        "repdata = tf.keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = repdata.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images.astype(np.float32) / 255.0\n",
        "test_images = test_images.astype(np.float32) / 255.0\n",
        "\n",
        "def representative_dataset_gen():\n",
        "  for input in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
        "    yield [input]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "with open('model_ffiq.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "azj-stLKBRY4",
        "outputId": "3b3dadce-fe69-4ebd-975d-aad6e7ed215b"
      },
      "outputs": [],
      "source": [
        "# Convert to Full integer quantization model (FIQ)\n",
        "\n",
        "# Load reperesenative dataset\n",
        "repdata = tf.keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = repdata.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images.astype(np.float32) / 255.0\n",
        "test_images = test_images.astype(np.float32) / 255.0\n",
        "\n",
        "def representative_dataset_gen():\n",
        "  for input in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
        "    yield [input]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "with open('model_drq.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Quantization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
